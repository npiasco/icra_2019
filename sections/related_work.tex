\section{Related Work}
\label{sec:related_work}

\subsection{Visual-based localization}\label{se:soa_VBL}
Visual-based localization area includes image retrieval-based methods that return the position and orientation of the closest example in the reference data pool. It consists in designing image descriptor dedicated to place recognition. Classical algorithms involve sparse features extraction and description combined with aggregation in order to produce global descriptors. Efficient nearest neighbor search is then used to recover the closest image (or the closest images) in the geo-referenced database~\cite{Arandjelovic2014,Torii2015}. Latest work introduce convolutional neural network for global features extraction~\cite{Arandjelovic2017,Kim2017a,Gordo2017,Radenovic2017,Sunderhauf2015a}.
%\vspace{5pt}
%\noindent Hence both branch of VBL methods can benefit from deep learning, we found natural to apply our learning with side modality approach to the localization task.

\subsection{Learning with side information}\label{se:soa_side}
\paragraph{Learning with side modality} Recent work on side modality learning have been applied for image classification~\cite{Zhang2014}. In this work, authors exploit extra-depth information or multi-spectral channels paired with images. Gupta et al.~\cite{Gupta2016a} use RGB images to train an effective classifier for depth modality with limited number of depth examples. The \textit{supervision transfer} is operated through deep features. The same research team~\cite{Hoffman2016a} explores the benefit of adding an auxiliary modality at test time although no example have been provided for this modality during the training process. The target task was object detection and categorization and the modalities involved were image and depth. The closest work to ours has been presented in~\cite{Hoffman2016}. Authors train a deep neural network to hallucinate features from a modality only present during the training process. In a same manner, Xu et al.~\cite{xu2017learning} use recreated thermal images to improve pedestrian detection.

\subsection{Modality transfer through CNN}\label{se:soa_CNN}
Deep neural network have recently proved high capability in modality transfer~\cite{Kuznietsov2017,Godard2017,xu2017learning}. In particular, fully convolutional architecture seems to be well suited for that task~\cite{Badrinarayanan2017}. For instance, estimating depth map from single RGB data is a challenging problem where fully convolutional network outperforms other methods~\cite{Kuznietsov2017,Godard2017}. Thermal map~\cite{xu2017learning} can also be learned from RGB images through deep neural net. Such network can also model dynamic changes across a single modality, like illumination variation~\cite{Yin2017} or inter-seasonal changes~\cite{zhu2017unpaired}. Based on these recent works, we note that fully convolutional architecture should be well suited for learning various modalities appearances.