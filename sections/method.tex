\section{Method}
\label{sec:method}

\begin{figure}
	\center
	\includegraphics[width=\linewidth]{vect/our_method}
	\caption{\label{fig:our_method} \textbf{Image descriptors training with auxiliary depth data:} two encoders are used for extracting deep features map from the main image modality and the auxiliary reconstructed depth map (inferred from our deep decoder). These features are used to create intermediate descriptors that are finally concatenated in one final image descriptor.}
\end{figure}

\begin{figure}
	\center
	\includegraphics[width=\linewidth]{vect/hall_method}
	\caption{\label{fig:hall_method} \textbf{Hallucination network for image descriptors learning:} we train an hallucination network, inpired from~\cite{Hoffman2016}, for the task of global image description. Unlike the proposed method (see figure~\ref{fig:our_method}), hallucination network reproduces feature maps that would have been obtained by a network trained with depth map rather than the deep map itself.}
\end{figure}



\subsection{Overview}
\label{subsec:overview}	

\subsection{Fine tuning with weakly annotated data}
\label{subsec:data}

\input{tab/data_requirement}
