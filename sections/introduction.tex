\section{Introduction}
\label{sec:intro}

Visual-Based Localization (VBL) is a central topic in robotics and computer vision applications~\cite{Piasco2017}. It consists in retrieving the location of a visual query according to a known absolute reference. VBL is used in many applications such as autonomous driving, augmented reality, urban navigation or automatic map updating. In this paper, we address the VBL as an image retrieval problem where an input image is compared to a reference pool of localized images. Numerous works have introduced image descriptors well suited for image retrieval for localization~\cite{Arandjelovic2017,Kim2017a,Gordo2017,Radenovic2017,Liu2018}. 

One of the main challenges of image based localization remains the mapping of images acquired under changing conditions: cross-season images matching~\cite{Naseer2017a}, long-term localization~\cite{Toft2018}, day to night place recognition~\cite{Torii2015}, etc. Recent approaches use complementary modalities in order to address visually challenging localization scenarios. Scene geometry is often used~\cite{Cavallari?,Schonberger2018}, as well as semantic interpretation~\cite{Ardeshir2014,Christie2016,Naseer2017a}. However geometric or semantic information are not always available, especially in robotic applications when the sensor or the computational load on the robot is limited.

In this paper we propose a method that learns from an image the corresponding scene geometry, in order to deal with challenging outdoor large-scale image based localization scenarios. We use paired images and depth maps to train an efficient descriptor. The geometric information provided during the training step makes our new descriptor robust to visual changes that occur between images taken at different times. Once trained, our system is used on images only to construct a powerful descriptor for image retrieval. This kind of system design is also known as side information learning~\cite{Hoffman2016}, as it uses geometric and radiometric information only during the training step and just radiometric data for the image localization. Our method is especially well suited for robot long-term localization when the perceptive sensor on the robot is limited to a camera~\cite{Middelberg2014}, but we have an off-line access to the full scene geometry~\cite{Paparoditis2012,Maddern2016,Wang2016}. 

The paper is organized as follows. We firstly review in section~\ref{sec:related_work} recent works related to our method including:~state of the art image descriptors for large scale outdoor localization, method for localization in changing environment and side information learning approaches. In section~\ref{sec:method}, we describe in detail our new image descriptor trained with side depth information. We illustrate the effectiveness of the proposed method on four challenging scenarios in section~\ref{sec:experiments}. Section~\ref{sec:conclusion} finally concludes the paper.